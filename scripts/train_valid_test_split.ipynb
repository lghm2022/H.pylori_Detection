{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9a3d05e-a7ae-4cbd-a5c9-f96d8e943140",
   "metadata": {},
   "source": [
    "# Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5077b081-c57d-47f0-8d21-4dc32b08c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c7e6be-cbfe-463b-940a-27713c1595c1",
   "metadata": {},
   "source": [
    "# Function for data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b4a4fac-3b9e-44f8-bd28-fb9850508034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(path_from_imgs, path_from_labels, path_to_imgs, path_to_labels, thresh):\n",
    "    '''\n",
    "    Function for splitting data proportionally\n",
    "    (i.e same proportion of labaled examples in the subsets as in the total set)\n",
    "    and saving the subset in specified paths\n",
    "    \n",
    "    Recieves:\n",
    "    path_from_imgs: path were the images are stored\n",
    "    path_from_labels: path were the labels are stored\n",
    "    path_to_imgs: path were the subset images will be saved\n",
    "    path_to_labels: path were the subset labels will be saved\n",
    "    thresh: proportion of the dataset that will be used for test (0 to 1)\n",
    "    \n",
    "    Returns nothing\n",
    "    '''\n",
    "    \n",
    "    random.seed(0) #set seed for reproductibility\n",
    "    \n",
    "    #Selection of the % of the labeled images for the test database\n",
    "    label_list = os.listdir(path_from_labels)\n",
    "    positive_subset_labels = random.sample(label_list, round(len(label_list)*thresh))\n",
    "    positive_subset_imgs = [sample.split('.')[0]+'.tiff' for sample in positive_subset_labels]    \n",
    "    \n",
    "    #Selection of the other images of the test database\n",
    "    image_list = os.listdir(path_from_imgs)\n",
    "\n",
    "    img_names = [img.split('.')[0] for img in image_list]\n",
    "    label_names = [label.split('.')[0] for label in label_list]\n",
    "\n",
    "    negative_cases = [name for name in img_names if name not in label_names]\n",
    "    negative_subset_n = round((len(positive_subset_imgs)*len(image_list))/len(label_list))\n",
    "    negative_subset = random.sample(negative_cases,negative_subset_n)\n",
    "    negative_subset = [sample+'.tiff' for sample in negative_subset]\n",
    "\n",
    "    subset_imgs = positive_subset_imgs + negative_subset\n",
    "    random.shuffle(subset_imgs)\n",
    "    \n",
    "    #check if path_to exists\n",
    "    if os.path.exists(path_to_labels) == False:\n",
    "        os.makedirs(path_to_labels)\n",
    "        \n",
    "    if os.path.exists(path_to_imgs) == False:\n",
    "        os.makedirs(path_to_imgs)\n",
    "    \n",
    "    #Send files to the test folder\n",
    "    for label in positive_subset_labels:\n",
    "        shutil.move(path_from_labels+'/'+label,path_to_labels)\n",
    "\n",
    "    for img in subset_imgs:\n",
    "        shutil.move(path_from_imgs+'/'+img,path_to_imgs)            \n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78441300-e452-45bc-bb17-9d4ba22bc192",
   "metadata": {},
   "source": [
    "# Test datset \n",
    "\n",
    "Made using 10% of the total dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae994000-f224-4ce5-ba54-e7eec8ebc9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_from_labels = '/home/ld_brito/DeepL/dataset description/dataset/labels'\n",
    "path_from_imgs = '/home/ld_brito/DeepL/dataset description/dataset/images'\n",
    "path_to_labels = '/home/ld_brito/DeepL/dataset description/test/labels'\n",
    "path_to_imgs = '/home/ld_brito/DeepL/dataset description/test/images'\n",
    "\n",
    "data_split(path_from_imgs,path_from_labels,path_to_imgs,path_to_labels,0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7e2d00-08d4-4ea0-913b-f55ac8738a7f",
   "metadata": {},
   "source": [
    "# Validation dataset\n",
    "\n",
    "Made using 30% of the remaining dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96db34fa-4c42-4d4a-ba09-5fcc99cf3a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_from_labels = '/home/ld_brito/DeepL/dataset description/dataset/labels'\n",
    "path_from_imgs = '/home/ld_brito/DeepL/dataset description/dataset/images'\n",
    "path_to_labels = '/home/ld_brito/DeepL/dataset description/valid/labels'\n",
    "path_to_imgs = '/home/ld_brito/DeepL/dataset description/valid/images'\n",
    "\n",
    "data_split(path_from_imgs,path_from_labels,path_to_imgs,path_to_labels,0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a957b11f-8f5a-4218-9a37-c1b5cf98e8a2",
   "metadata": {},
   "source": [
    "# Train dataset\n",
    "\n",
    "After the test and validation subsets, the remaining data will be renamed to be the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b386a91-94f4-4ccc-a06b-1fb071909c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rename('/home/ld_brito/DeepL/dataset description/dataset',\n",
    "          '/home/ld_brito/DeepL/dataset description/train')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
